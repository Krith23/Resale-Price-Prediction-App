{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "613ab992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba01b4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading models: No module named '_loss'\n",
      "Models could not be loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_models():\n",
    "    try:\n",
    "        meta_model = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\meta_model.pkl')\n",
    "        rf = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\random_forest_model.joblib')\n",
    "        gb = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\gradient_boosting_model.joblib')\n",
    "\n",
    "        # Load XGBoost model using its load_model method\n",
    "        xgb = XGBRegressor()  # Create an instance of XGBRegressor\n",
    "        xgb.load_model('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\xgb_model.json')  # Load the model from JSON file\n",
    "\n",
    "        lr = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\linear_regression_model.joblib')\n",
    "        dt = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\decision_tree_model.joblib')\n",
    "\n",
    "        scaler = joblib.load('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\HDBApp\\\\scaler.pkl')\n",
    "\n",
    "        return rf, gb, xgb, lr, dt, meta_model, scaler\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {e}\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "# Load the models\n",
    "rf, gb, xgb, lr, dt, meta_model, scaler = load_models()\n",
    "\n",
    "# Check if models are loaded correctly\n",
    "if rf is not None and gb is not None and xgb is not None and lr is not None and dt is not None and meta_model is not None:\n",
    "    # Load your validation DataFrame here\n",
    "    val_df = pd.read_csv('C:\\\\Users\\\\Krithika JK\\\\Documents\\\\GitHub\\\\FYP\\\\data\\\\hdb_val.csv')  # Ensure you have the correct path\n",
    "\n",
    "    # Display the first few rows of the validation DataFrame\n",
    "#     print(\"Validation Data Preview:\")\n",
    "#     print(val_df.head(5))\n",
    "\n",
    "    # Prepare the validation DataFrame similarly to input_df\n",
    "    val_input_df = val_df.copy()\n",
    "\n",
    "    # One-hot encoding for categorical variables in validation set\n",
    "    towns = ['ANG MO KIO', 'BEDOK', 'BISHAN', 'BUKIT BATOK', 'BUKIT MERAH',\n",
    "             'BUKIT TIMAH', 'CENTRAL AREA', 'CHOA CHU KANG', 'CLEMENTI',\n",
    "             'GEYLANG', 'HOUGANG', 'JURONG EAST', 'JURONG WEST',\n",
    "             'KALLANG/WHAMPOA', 'MARINE PARADE', 'QUEENSTOWN', 'SENGKANG',\n",
    "             'SERANGOON', 'TAMPINES', 'TOA PAYOH', 'WOODLANDS', 'YISHUN',\n",
    "             'LIM CHU KANG', 'SEMBAWANG', 'BUKIT PANJANG', 'PASIR RIS',\n",
    "             'PUNGGOL']\n",
    "             \n",
    "    flat_types = ['1 ROOM', '2 ROOM', '3 ROOM', '4 ROOM', '5 ROOM', 'EXECUTIVE', 'MULTI GENERATION']\n",
    "    flat_models = ['Improved', 'New Generation', 'Model A', 'Standard', 'Simplified',\n",
    "                   'Model A-Maisonette', 'Apartment', 'Maisonette', 'Terrace',\n",
    "                   '2-Room', 'Improved-Maisonette', 'Multi Generation',\n",
    "                   'Premium Apartment', 'Adjoined flat', 'Premium Maisonette',\n",
    "                   'Model A2', 'DBSS', 'Type S1', 'Type S2', 'Premium Apartment Loft',\n",
    "                   '3Gen']\n",
    "\n",
    "    for town in towns:\n",
    "        val_input_df[f'town_{town}'] = val_input_df['town'].apply(lambda x: 1 if x == town else 0)\n",
    "\n",
    "    for flat_type in flat_types:\n",
    "        val_input_df[f'flat_type_{flat_type}'] = val_input_df['flat_type'].apply(lambda x: 1 if x == flat_type else 0)\n",
    "\n",
    "    for flat_model in flat_models:\n",
    "        val_input_df[f'flat_model_{flat_model}'] = val_input_df['flat_model'].apply(lambda x: 1 if x == flat_model else 0)\n",
    "\n",
    "    # Ensure the expected columns for the validation DataFrame\n",
    "    expected_columns = ['floor_area_sqm', 'nearest_supermarket_distance', 'nearest_school_distance', 'nearest_mrt_distance', \n",
    "                        'nearest_hawkers_distance', 'cbd_distance', 'year_of_sale', 'calculated_remaining_lease', \n",
    "                        'storey_median', 'town_BEDOK', 'town_BISHAN', 'town_BUKIT BATOK', 'town_BUKIT MERAH', \n",
    "                        'town_BUKIT PANJANG', 'town_BUKIT TIMAH', 'town_CENTRAL AREA', 'town_CHO CHU KANG', \n",
    "                        'town_CLEMENTI', 'town_GEYLANG', 'town_HOUGANG', 'town_JURONG EAST', 'town_JURONG WEST', \n",
    "                        'town_KALLANG/WHAMPOA', 'town_LIM CHU KANG', 'town_MARINE PARADE', 'town_PASIR RIS', \n",
    "                        'town_PUNGGOL', 'town_QUEENSTOWN', 'town_SEMBAWANG', 'town_SENGKANG', 'town_SERANGOON', \n",
    "                        'town_TAMPINES', 'town_TOA PAYOH', 'town_WOODLANDS', 'town_YISHUN', 'flat_model_3Gen', \n",
    "                        'flat_model_Adjoined flat', 'flat_model_Apartment', 'flat_model_DBSS', 'flat_model_Improved', \n",
    "                        'flat_model_Improved-Maisonette', 'flat_model_Maisonette', 'flat_model_Model A', \n",
    "                        'flat_model_Model A-Maisonette', 'flat_model_Model A2', 'flat_model_Multi Generation', \n",
    "                        'flat_model_New Generation', 'flat_model_Premium Apartment', 'flat_model_Premium Apartment Loft', \n",
    "                        'flat_model_Premium Maisonette', 'flat_model_Simplified', 'flat_model_Standard', 'flat_model_Terrace', \n",
    "                        'flat_model_Type S1', 'flat_model_Type S2', 'flat_type_2 ROOM', 'flat_type_3 ROOM', 'flat_type_4 ROOM', \n",
    "                        'flat_type_5 ROOM', 'flat_type_EXECUTIVE', 'flat_type_MULTI GENERATION']\n",
    "\n",
    "    val_input_df = val_input_df.reindex(columns=expected_columns, fill_value=0)\n",
    "\n",
    "    # Scale validation data\n",
    "    val_input_scaled = scaler.transform(val_input_df)\n",
    "\n",
    "    # Make predictions on the validation DataFrame\n",
    "    rf_val_pred = rf.predict(val_input_scaled)\n",
    "    gb_val_pred = gb.predict(val_input_scaled)\n",
    "    xgb_val_pred = xgb.predict(val_input_scaled)\n",
    "    lr_val_pred = lr.predict(val_input_scaled)\n",
    "    dt_val_pred = dt.predict(val_input_scaled)\n",
    "\n",
    "    # Combine predictions for meta-model\n",
    "    X_val_meta = np.column_stack((rf_val_pred, gb_val_pred, lr_val_pred, xgb_val_pred, dt_val_pred))\n",
    "\n",
    "    # Final predictions using meta-model\n",
    "    y_val_pred = meta_model.predict(X_val_meta)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    rmse = root_mean_squared_error(val_df['resale_price'], y_val_pred)\n",
    "    mae = mean_absolute_error(val_df['resale_price'], y_val_pred)\n",
    "    r2 = r2_score(val_df['resale_price'], y_val_pred)\n",
    "\n",
    "    # Display the evaluation metrics\n",
    "    print(\"### Evaluation Metrics on Validation DataFrame:\")\n",
    "    print(f\"**RMSE:** {rmse:.2f}\")\n",
    "    print(f\"**MAE:** {mae:.2f}\")\n",
    "    print(f\"**RÂ²:** {r2:.2f}\")\n",
    "\n",
    "    # Plot predicted vs actual values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(val_df['resale_price'], y_val_pred, alpha=0.7)\n",
    "    plt.plot([val_df['resale_price'].min(), val_df['resale_price'].max()],\n",
    "             [val_df['resale_price'].min(), val_df['resale_price'].max()],\n",
    "             'r--', lw=2)\n",
    "    plt.title('Predicted vs Actual Resale Prices')\n",
    "    plt.xlabel('Actual Resale Price')\n",
    "    plt.ylabel('Predicted Resale Price')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Models could not be loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058dded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
